{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# data_road\n",
    "train_data = pd.read_csv(\"../data/train.tsv\", delimiter='\\t')\n",
    "test_data = pd.read_csv(\"../data/test.tsv\", delimiter='\\t')\n",
    "x, y = train_data.iloc[:, 3:21], train_data[\"LeagueIndex\"]-1\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y)\n",
    "x_test= test_data.iloc[:, 2:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:04:42] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_eek2t0c4ro/croots/recipe/xgboost-split_1659548960591/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-mlogloss:1.69932\tvali-mlogloss:1.85520\n",
      "[1]\ttrain-mlogloss:1.45983\tvali-mlogloss:1.73357\n",
      "[2]\ttrain-mlogloss:1.28681\tvali-mlogloss:1.64832\n",
      "[3]\ttrain-mlogloss:1.14916\tvali-mlogloss:1.58188\n",
      "[4]\ttrain-mlogloss:1.02678\tvali-mlogloss:1.54110\n",
      "[5]\ttrain-mlogloss:0.94172\tvali-mlogloss:1.50049\n",
      "[6]\ttrain-mlogloss:0.85502\tvali-mlogloss:1.47051\n",
      "[7]\ttrain-mlogloss:0.78824\tvali-mlogloss:1.44621\n",
      "[8]\ttrain-mlogloss:0.73124\tvali-mlogloss:1.42759\n",
      "[9]\ttrain-mlogloss:0.66798\tvali-mlogloss:1.41847\n",
      "time:0.16503310203552246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sugarl/.conda/envs/data_final/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "xgb_params = {'objective': 'multi:softmax', 'num_class': 8}\n",
    "\n",
    "evals = [(dtrain, 'train'), (dvalid, 'vali')]\n",
    "\n",
    "xgb_model = xgb.train(xgb_params,\n",
    "                      dtrain,\n",
    "                      evals=evals,\n",
    "                      )\n",
    "\n",
    "print('time:{}'.format(time.time()-start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:0.3976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = xgb_model.predict(dvalid)\n",
    "score = accuracy_score(y_val, pred)\n",
    "print('score:{0:.4f}'.format(score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3798\n",
      "[LightGBM] [Info] Number of data points in the train set: 1272, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -2.914239\n",
      "[LightGBM] [Info] Start training from score -2.221092\n",
      "[LightGBM] [Info] Start training from score -1.830226\n",
      "[LightGBM] [Info] Start training from score -1.405343\n",
      "[LightGBM] [Info] Start training from score -1.451252\n",
      "[LightGBM] [Info] Start training from score -1.787054\n",
      "[LightGBM] [Info] Start training from score -4.103823\n",
      "[LightGBM] [Info] Start training from score -4.315132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tTrain's multi_logloss: 1.56998\tValid's multi_logloss: 1.64814\n",
      "[2]\tTrain's multi_logloss: 1.43776\tValid's multi_logloss: 1.58928\n",
      "[3]\tTrain's multi_logloss: 1.3304\tValid's multi_logloss: 1.54484\n",
      "[4]\tTrain's multi_logloss: 1.23709\tValid's multi_logloss: 1.51022\n",
      "[5]\tTrain's multi_logloss: 1.15443\tValid's multi_logloss: 1.47981\n",
      "[6]\tTrain's multi_logloss: 1.08227\tValid's multi_logloss: 1.45811\n",
      "[7]\tTrain's multi_logloss: 1.01585\tValid's multi_logloss: 1.43999\n",
      "[8]\tTrain's multi_logloss: 0.954058\tValid's multi_logloss: 1.42736\n",
      "[9]\tTrain's multi_logloss: 0.899289\tValid's multi_logloss: 1.41541\n",
      "[10]\tTrain's multi_logloss: 0.848309\tValid's multi_logloss: 1.40561\n",
      "[11]\tTrain's multi_logloss: 0.800802\tValid's multi_logloss: 1.40011\n",
      "[12]\tTrain's multi_logloss: 0.756334\tValid's multi_logloss: 1.39666\n",
      "[13]\tTrain's multi_logloss: 0.714606\tValid's multi_logloss: 1.39103\n",
      "[14]\tTrain's multi_logloss: 0.675167\tValid's multi_logloss: 1.38321\n",
      "[15]\tTrain's multi_logloss: 0.638587\tValid's multi_logloss: 1.38185\n",
      "[16]\tTrain's multi_logloss: 0.60458\tValid's multi_logloss: 1.37928\n",
      "[17]\tTrain's multi_logloss: 0.572726\tValid's multi_logloss: 1.37481\n",
      "[18]\tTrain's multi_logloss: 0.542337\tValid's multi_logloss: 1.37\n",
      "[19]\tTrain's multi_logloss: 0.51459\tValid's multi_logloss: 1.36756\n",
      "[20]\tTrain's multi_logloss: 0.487497\tValid's multi_logloss: 1.36568\n",
      "[21]\tTrain's multi_logloss: 0.462423\tValid's multi_logloss: 1.36362\n",
      "[22]\tTrain's multi_logloss: 0.438615\tValid's multi_logloss: 1.35946\n",
      "[23]\tTrain's multi_logloss: 0.414973\tValid's multi_logloss: 1.36078\n",
      "[24]\tTrain's multi_logloss: 0.394984\tValid's multi_logloss: 1.36307\n",
      "[25]\tTrain's multi_logloss: 0.374481\tValid's multi_logloss: 1.36551\n",
      "[26]\tTrain's multi_logloss: 0.355395\tValid's multi_logloss: 1.36804\n",
      "[27]\tTrain's multi_logloss: 0.337032\tValid's multi_logloss: 1.36949\n",
      "[28]\tTrain's multi_logloss: 0.319679\tValid's multi_logloss: 1.37511\n",
      "[29]\tTrain's multi_logloss: 0.303509\tValid's multi_logloss: 1.37536\n",
      "[30]\tTrain's multi_logloss: 0.287578\tValid's multi_logloss: 1.3794\n",
      "[31]\tTrain's multi_logloss: 0.274288\tValid's multi_logloss: 1.38421\n",
      "[32]\tTrain's multi_logloss: 0.260219\tValid's multi_logloss: 1.38852\n",
      "[33]\tTrain's multi_logloss: 0.248047\tValid's multi_logloss: 1.39328\n",
      "[34]\tTrain's multi_logloss: 0.236338\tValid's multi_logloss: 1.40015\n",
      "[35]\tTrain's multi_logloss: 0.224448\tValid's multi_logloss: 1.40242\n",
      "[36]\tTrain's multi_logloss: 0.213782\tValid's multi_logloss: 1.40955\n",
      "[37]\tTrain's multi_logloss: 0.203603\tValid's multi_logloss: 1.42009\n",
      "[38]\tTrain's multi_logloss: 0.19372\tValid's multi_logloss: 1.42558\n",
      "[39]\tTrain's multi_logloss: 0.184302\tValid's multi_logloss: 1.42735\n",
      "[40]\tTrain's multi_logloss: 0.175802\tValid's multi_logloss: 1.43328\n",
      "[41]\tTrain's multi_logloss: 0.167059\tValid's multi_logloss: 1.43612\n",
      "[42]\tTrain's multi_logloss: 0.158783\tValid's multi_logloss: 1.43891\n",
      "[43]\tTrain's multi_logloss: 0.15136\tValid's multi_logloss: 1.44629\n",
      "[44]\tTrain's multi_logloss: 0.144081\tValid's multi_logloss: 1.45289\n",
      "[45]\tTrain's multi_logloss: 0.137624\tValid's multi_logloss: 1.46061\n",
      "[46]\tTrain's multi_logloss: 0.131067\tValid's multi_logloss: 1.46294\n",
      "[47]\tTrain's multi_logloss: 0.124728\tValid's multi_logloss: 1.4706\n",
      "[48]\tTrain's multi_logloss: 0.119006\tValid's multi_logloss: 1.47714\n",
      "[49]\tTrain's multi_logloss: 0.113425\tValid's multi_logloss: 1.47943\n",
      "[50]\tTrain's multi_logloss: 0.108216\tValid's multi_logloss: 1.48684\n",
      "[51]\tTrain's multi_logloss: 0.103045\tValid's multi_logloss: 1.49082\n",
      "[52]\tTrain's multi_logloss: 0.0982645\tValid's multi_logloss: 1.49567\n",
      "[53]\tTrain's multi_logloss: 0.0935516\tValid's multi_logloss: 1.50248\n",
      "[54]\tTrain's multi_logloss: 0.0894103\tValid's multi_logloss: 1.50936\n",
      "[55]\tTrain's multi_logloss: 0.0852789\tValid's multi_logloss: 1.51585\n",
      "[56]\tTrain's multi_logloss: 0.0812287\tValid's multi_logloss: 1.51964\n",
      "[57]\tTrain's multi_logloss: 0.0774821\tValid's multi_logloss: 1.52454\n",
      "[58]\tTrain's multi_logloss: 0.0740095\tValid's multi_logloss: 1.53103\n",
      "[59]\tTrain's multi_logloss: 0.0706057\tValid's multi_logloss: 1.53613\n",
      "[60]\tTrain's multi_logloss: 0.067333\tValid's multi_logloss: 1.54504\n",
      "[61]\tTrain's multi_logloss: 0.0642539\tValid's multi_logloss: 1.54868\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tTrain's multi_logloss: 0.0611775\tValid's multi_logloss: 1.55351\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tTrain's multi_logloss: 0.0584194\tValid's multi_logloss: 1.55785\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tTrain's multi_logloss: 0.055708\tValid's multi_logloss: 1.56507\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tTrain's multi_logloss: 0.05319\tValid's multi_logloss: 1.56683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tTrain's multi_logloss: 0.0508839\tValid's multi_logloss: 1.57472\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tTrain's multi_logloss: 0.0485042\tValid's multi_logloss: 1.58245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tTrain's multi_logloss: 0.0463242\tValid's multi_logloss: 1.5892\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tTrain's multi_logloss: 0.0441492\tValid's multi_logloss: 1.59607\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tTrain's multi_logloss: 0.0421445\tValid's multi_logloss: 1.60243\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tTrain's multi_logloss: 0.0402208\tValid's multi_logloss: 1.60726\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tTrain's multi_logloss: 0.0383089\tValid's multi_logloss: 1.61505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tTrain's multi_logloss: 0.0366696\tValid's multi_logloss: 1.62207\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tTrain's multi_logloss: 0.0350203\tValid's multi_logloss: 1.62788\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tTrain's multi_logloss: 0.0334609\tValid's multi_logloss: 1.63247\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tTrain's multi_logloss: 0.031958\tValid's multi_logloss: 1.6369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tTrain's multi_logloss: 0.0304512\tValid's multi_logloss: 1.64304\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tTrain's multi_logloss: 0.0291402\tValid's multi_logloss: 1.65349\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tTrain's multi_logloss: 0.0278283\tValid's multi_logloss: 1.66276\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tTrain's multi_logloss: 0.0265778\tValid's multi_logloss: 1.66971\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tTrain's multi_logloss: 0.0253076\tValid's multi_logloss: 1.6763\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tTrain's multi_logloss: 0.0242726\tValid's multi_logloss: 1.68317\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tTrain's multi_logloss: 0.0231756\tValid's multi_logloss: 1.68945\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[84]\tTrain's multi_logloss: 0.0221288\tValid's multi_logloss: 1.69651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tTrain's multi_logloss: 0.0211814\tValid's multi_logloss: 1.70367\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[86]\tTrain's multi_logloss: 0.0202239\tValid's multi_logloss: 1.70812\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[87]\tTrain's multi_logloss: 0.0193267\tValid's multi_logloss: 1.71717\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tTrain's multi_logloss: 0.0184648\tValid's multi_logloss: 1.72142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[89]\tTrain's multi_logloss: 0.0176641\tValid's multi_logloss: 1.72921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tTrain's multi_logloss: 0.0169102\tValid's multi_logloss: 1.73698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[91]\tTrain's multi_logloss: 0.0160778\tValid's multi_logloss: 1.74601\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[92]\tTrain's multi_logloss: 0.0153789\tValid's multi_logloss: 1.75404\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\tTrain's multi_logloss: 0.0146474\tValid's multi_logloss: 1.76124\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[94]\tTrain's multi_logloss: 0.0139848\tValid's multi_logloss: 1.76585\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[95]\tTrain's multi_logloss: 0.01338\tValid's multi_logloss: 1.77564\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\tTrain's multi_logloss: 0.0127593\tValid's multi_logloss: 1.78489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[97]\tTrain's multi_logloss: 0.0121484\tValid's multi_logloss: 1.78996\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\tTrain's multi_logloss: 0.0116123\tValid's multi_logloss: 1.79597\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[99]\tTrain's multi_logloss: 0.0111156\tValid's multi_logloss: 1.80168\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tTrain's multi_logloss: 0.010627\tValid's multi_logloss: 1.80581\n",
      "elapsed_time:0.7686588764190674\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_val = lgb.Dataset(x_val, y_val, reference=lgb_train)\n",
    "lgb_test = lgb.Dataset(x_test)\n",
    "\n",
    "params = {'objective' : 'multiclass','num_class' : 8}\n",
    "\n",
    "lgb_model = lgb.train(params=params,\n",
    "                        train_set=lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_val],\n",
    "                        valid_names=['Train', 'Valid'])\n",
    "\n",
    "print('elapsed_time:{}'.format(time.time()-start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:0.4306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lgb_pred = lgb_model.predict(x_val)\n",
    "lgb_pred_low = np.argmax(lgb_pred, axis=1)\n",
    "score = accuracy_score(y_val, lgb_pred_low)\n",
    "print('score:{0:.4f}'.format(score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "y_pred = lgb_model.predict(x_test)\n",
    "y_pred_max = np.argmax(y_pred, axis=1)\n",
    "with open(\"../result/lightgbm_test.csv\", \"w\") as csv_file:\n",
    "    for pred_low, test_id in zip(y_pred_max, test_data['Unnamed: 0']):\n",
    "        writer = csv.writer(csv_file)\n",
    "        low = [test_id, int(pred_low+1)]\n",
    "        writer.writerow(low)\n",
    "\n",
    "    csv_file.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:0.4306\n"
     ]
    }
   ],
   "source": [
    "cat_pred = lgb_model.predict(x_val)\n",
    "cat_pred_low = np.argmax(lgb_pred, axis=1)\n",
    "score = accuracy_score(y_val, cat_pred_low)\n",
    "print('score:{0:.4f}'.format(score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:4.368575811386108\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 専用の型に変換\n",
    "catb_train = cb.Pool(x_train, label=y_train)\n",
    "catb_valid = cb.Pool(x_val, label=y_val)\n",
    "catb_test = cb.Pool(x_test)\n",
    "\n",
    "# パラメータを設定\n",
    "params = {'loss_function': 'MultiClass'}\n",
    "\n",
    "# 学習\n",
    "catb_model = cb.CatBoost(params)\n",
    "catb_model.fit(catb_train,\n",
    "               eval_set=[catb_valid],\n",
    "               verbose=False)\n",
    "\n",
    "print('elapsed_time:{}'.format(time.time()-start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1698, 8)\n"
     ]
    }
   ],
   "source": [
    "print(cat_pred.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "cat_pred = catb_model.predict(catb_test)\n",
    "cat_pred_sca = np.argmax(cat_pred, axis=1)\n",
    "with open(\"../result/catboost_test.csv\", \"w\") as csv_file:\n",
    "    for pred_low, test_id in zip(cat_pred_sca, test_data['Unnamed: 0']):\n",
    "        writer = csv.writer(csv_file)\n",
    "        low = [test_id, int(pred_low+1)]\n",
    "        writer.writerow(low)\n",
    "\n",
    "    csv_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def k_fold_cv(x, y, model, k):\n",
    "    cv = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "    mse_list = []\n",
    "    for train_index, test_index in cv.split(x):\n",
    "        # get train and test data\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # fit model\n",
    "        model.fit(x_train, y_train)\n",
    "        # predict test data\n",
    "        y_pred = model.predict(x_test)\n",
    "        # loss\n",
    "        mse = np.mean((y_pred - y_test)**2)\n",
    "        mse_list.append(mse)\n",
    "    print(f\"MSE({k}FoldCV): {np.mean(mse_list)}\")\n",
    "    print(f\"std: {np.std(mse_list)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}